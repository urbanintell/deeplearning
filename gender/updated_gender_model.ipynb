{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "import keras\n",
    "import os, shutil\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras .callbacks import TensorBoard\n",
    "from tensorflow.keras  import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from PIL import ImageFile\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_women_dir = './gender/Female'\n",
    "base_dir = './gender/categories'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "train_women_dir = os.path.join(train_dir, 'women')\n",
    "validation_women_dir = os.path.join(validation_dir, 'women')\n",
    "test_women_dir = os.path.join(test_dir, 'women')\n",
    "\n",
    "\n",
    "train_men_dir = os.path.join(train_dir, 'men')\n",
    "validation_men_dir = os.path.join(validation_dir, 'men')\n",
    "test_men_dir = os.path.join(test_dir, 'men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training male images: 700\n",
      "total training female images: 679\n",
      "total validation male images: 50\n",
      "total validation female images: 57\n",
      "total test male images: 246\n",
      "total test women images: 251\n"
     ]
    }
   ],
   "source": [
    "print('total training male images:', len(os.listdir(train_men_dir)))\n",
    "print('total training female images:', len(os.listdir(train_women_dir)))\n",
    "print('total validation male images:', len(os.listdir(validation_men_dir)))\n",
    "print('total validation female images:', len(os.listdir(validation_women_dir)))\n",
    "print('total test male images:', len(os.listdir(test_men_dir)))\n",
    "print('total test women images:', len(os.listdir(test_women_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 26, 40, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 11, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 1544      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 30,193\n",
      "Trainable params: 30,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters should not exceed number of datapoints in training per label by a factor of 10.\n",
    "# small dataste NN was able to memorize was not able to generalize\n",
    "# model can capture variations\n",
    "# smaller means number of parameters \n",
    "# increasing layers m decrease parameters\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28, 42, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# sgd = optimizers.SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = optimizers.RMSprop(lr=1e-2, decay=1e-6)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=rmsprop,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1377 images belonging to 2 classes.\n",
      "Found 105 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# decreased batch size from 10 to 5\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x225\n",
    "        target_size=(28, 42),\n",
    "        batch_size=16,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(28, 42),\n",
    "        batch_size=5,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 999/1000 [============================>.] - ETA: 18s - loss: 0.7010 - acc: 0.5004\n",
      "Epoch 00001: val_acc improved from -inf to 0.46650, saving model to checkpoint.01.hdf5\n",
      "1000/1000 [==============================] - 57066s 57s/step - loss: 0.7010 - acc: 0.5007 - val_loss: 0.6958 - val_acc: 0.4665\n",
      "Epoch 2/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.5016\n",
      "Epoch 00002: val_acc improved from 0.46650 to 0.46750, saving model to checkpoint.02.hdf5\n",
      "1000/1000 [==============================] - 388s 388ms/step - loss: 0.6934 - acc: 0.5015 - val_loss: 0.6941 - val_acc: 0.4675\n",
      "Epoch 3/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.5028\n",
      "Epoch 00003: val_acc did not improve from 0.46750\n",
      "1000/1000 [==============================] - 933s 933ms/step - loss: 0.6935 - acc: 0.5029 - val_loss: 0.6938 - val_acc: 0.4670\n",
      "Epoch 4/50\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.5013\n",
      "Epoch 00004: val_acc did not improve from 0.46750\n",
      "1000/1000 [==============================] - 337s 337ms/step - loss: 0.6935 - acc: 0.5011 - val_loss: 0.6951 - val_acc: 0.4665\n"
     ]
    }
   ],
   "source": [
    "val_loss_early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.1,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "val_acc_early_stop = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=0.1,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "CHECKPOINT_FILE_PATH = 'checkpoint.{epoch:02d}.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(CHECKPOINT_FILE_PATH,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Improvement after changing optimizer: https://keras.io/optimizers/\n",
    "# Added SGD optimizer\n",
    "# https://stackoverflow.com/questions/37213388/keras-accuracy-does-not-change\n",
    "\n",
    "# board = TensorBoard(log_dir='./output',\n",
    "#                             histogram_freq=0,\n",
    "#                             batch_size=16,\n",
    "#                             write_graph=True,\n",
    "#                             write_grads=False,\n",
    "#                             write_images=False,\n",
    "#                             embeddings_layer_names=None,\n",
    "#                             embeddings_metadata=None,\n",
    "#                             embeddings_data=None)\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=1000,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=400,\n",
    "      shuffle=True,\n",
    "      callbacks=[checkpoint,val_acc_early_stop,val_loss_early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model.save('thesatorialist.h5')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
